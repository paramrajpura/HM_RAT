{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89aa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiled from the previous works :\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/synch_editedbyOzge.py\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/Exctract_LEDs_28_01_2023.ipynb\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/synchronization.py\n",
    "\n",
    "# Author: Param Rajpura\n",
    "# 28th May 2023\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks,peak_prominences\n",
    "from datetime import datetime , time , timedelta\n",
    "import re\n",
    "import functools as ft\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443c857",
   "metadata": {},
   "source": [
    "# Extract file paths from the user defined basepath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1614b",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " The basepath must contain the following files:\n",
    " 1. Eye video files: .mp4 formats (12 files for each eye)\n",
    " 2. X,y co-ordinates of crops for LED positions : .led_crop format (1 file containing 12 xy co-ordinates)\n",
    " 3. Time stamp files containing framewise clock timestamps after linear regression: .csv format (12 files)\n",
    "    Note: TODO: Add the logic of meta to .csv conversion using Linear regression in this script.\n",
    " 4. Time stamps recorded from LED controller referred to as DIO: .dat format (3 files for red,blue and \n",
    " initial systime)\n",
    "     a. Rat4_20201109_maze.dio_MCU_Din1.dat for initial time stamp\n",
    "     b. Rat4_20201109_maze_merged.dio_MCU_Din1.dat for blue DIO\n",
    "     c. Rat4_20201109_maze_merged.dio_MCU_Din2.dat for red DIO\n",
    " '''\n",
    "\n",
    "\n",
    "# Reads all the mp4 files in the folder, checks for a led_crop_coordinates file and meta file\n",
    "def get_video_files_with_metadata(basepath,led_xy=True,time_stamp=True):\n",
    "    path = Path(basepath).resolve()\n",
    "    videos_filepath_list = list(sorted(path.glob('*eye*.mp4')))\n",
    "#     print(videos_filepath_list)\n",
    "    \n",
    "    crop_xy_dict = {}\n",
    "    # Verify if led_coordinates supplied\n",
    "    if led_xy:\n",
    "        crop_file_list = list(sorted(path.glob('*.led_crop')))\n",
    "#         print(crop_file_list)\n",
    "        if crop_file_list:\n",
    "            # read crops coords for each video and store\n",
    "            with open(crop_file_list[0]) as f:\n",
    "                crop_txt = f.readlines()\n",
    "#                 print(crop_txt)\n",
    "            for line in tqdm(crop_txt):\n",
    "                try:\n",
    "                    vid_path, x, y = line.split(',')\n",
    "                    crop_xy_dict[vid_path] = (int(x), int(y))\n",
    "                except ValueError:\n",
    "                    print(\"Faulty line:\", line, 'Maybe led coordinates are missing?')\n",
    "                    break\n",
    "        else:\n",
    "            raise Exception(\"File containing led crop coordinates not found.\")\n",
    "    if time_stamp:\n",
    "        # csv files no longer required since ts data extracted from meta files\n",
    "#         tsdata_filepath_list = list(sorted(path.glob('*.csv')))\n",
    "        meta_filepath_list = list(sorted(path.glob('*.meta')))\n",
    "        \n",
    "    #TODO: Verify for single file path in the list to avoid conflicting data\n",
    "    dio_file_path_dict={}\n",
    "    dio_file_path_dict['init'] = list(sorted(path.glob('*maze.*.dat')))\n",
    "    \n",
    "    dio_file_path_dict['blue'] = list(sorted(path.glob('*maze_merged*Din1.dat')))\n",
    "    dio_file_path_dict['red'] = list(sorted(path.glob('*maze_merged*Din2.dat')))\n",
    "    return videos_filepath_list,crop_xy_dict,meta_filepath_list,dio_file_path_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640dc74",
   "metadata": {},
   "source": [
    "# Functions to extract LED signals from video data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ica_signals(demixed, mix_weights,time_meta):\n",
    "    fps = 30.0\n",
    "    eD = 0.5       # expected Duty cycle of 0.5\n",
    "    ef_red = 0.5   # expected frequency of 0.5 Hz\n",
    "    ef_blue = 2.5  # expected frequency of 2.5 Hz\n",
    "    \n",
    "    dD = np.zeros(demixed.shape[1])\n",
    "    df_red = np.zeros(demixed.shape[1])\n",
    "    df_blue = np.zeros(demixed.shape[1])\n",
    "    \n",
    "    colors = {0: 'red', 1: 'blue', None: 'gray'}\n",
    "    N = -1\n",
    "    N_ICA = -1  # numbers of samples to use for ICA, -1 for all\n",
    "    \n",
    "    # This ensures if video crop is improper or signal corrupted, that eye is ignored\n",
    "    df_red_out = None\n",
    "    df_blue_out = None\n",
    "    \n",
    "    for n in range(demixed.shape[1]):\n",
    "\n",
    "        # Check the mixing weights if the demixed signal polarity is reversed\n",
    "        # (negative weights for ROI. Assuming rest of pixel array has weight zero, mean weight tells us sign.)\n",
    "        flip_ica = mix_weights[n] < 0\n",
    "        if flip_ica:\n",
    "            demixed[:, n] = -demixed[:, n]\n",
    "\n",
    "        km = KMeans(n_clusters=2, random_state=0).fit(demixed[:, n].reshape(-1, 1))\n",
    "        y_km = km.predict(demixed[:, n].reshape(-1, 1))\n",
    "\n",
    "        # check polarity, if necessary flip to match pulse polarity\n",
    "        # print(f'Centers: {float(km.cluster_centers_[0]*1000):.2f}, {float(km.cluster_centers_[1]*1000):.2f}')\n",
    "        centers = km.cluster_centers_.ravel()\n",
    "\n",
    "        flip_kmeans = centers[0] > centers[1]\n",
    "        flip = flip_ica ^ flip_kmeans\n",
    "        # print(f'Polarity FLIP: {flip} (ICA {flip_ica}, kmeans {flip_kmeans})')\n",
    "        if flip_kmeans:\n",
    "            # print('Flipping!')\n",
    "            y_km = np.abs(y_km-1)\n",
    "\n",
    "        duty_cycle = y_km.sum()/len(y_km)\n",
    "        freq = (np.diff(y_km)>0).sum()/len(y_km) * fps\n",
    "        dD[n] = abs(eD-duty_cycle)\n",
    "        df_red[n] = abs(ef_red - freq)\n",
    "        df_blue[n] = abs(ef_blue - freq)\n",
    "\n",
    "        # Attempt to identify the ICA signal as a color LED\n",
    "        good_DC = dD[n] < 0.2 * eD\n",
    "        good_freq = np.array([df_red[n] < ef_red * 0.1, df_blue[n] < ef_blue * 0.1])\n",
    "        is_signal = good_DC and good_freq.sum()\n",
    "        signal_color = good_freq.argmax() if is_signal else None\n",
    "        print(f\"ICA signal number: {n}, DutyCycle:{duty_cycle}, Freq:{freq}\")\n",
    "        sig_col = colors[signal_color]\n",
    "        sig_name = 'None' if signal_color is None else colors[signal_color]\n",
    "        \n",
    "        if sig_col=='red':\n",
    "            a = y_km[:N]\n",
    "            df_red_out = pd.DataFrame({'key' : [], \"LED_Intensity\" : []})\n",
    "            # \"Red_LED_Intensity_%s\" %(eye)\n",
    "            df_red_out['key'] = time_meta[0:(len(demixed[:N, n]-1))]\n",
    "            df_red_out[\"LED_Intensity\"] = demixed[:N, n]\n",
    "        elif sig_col=='blue':\n",
    "            a = y_km[:N]\n",
    "            df_blue_out = pd.DataFrame({'key' : [], \"LED_Intensity\" : []})\n",
    "            # \"Red_LED_Intensity_%s\" %(eye)\n",
    "            df_blue_out['key'] = time_meta[0:(len(demixed[:N, n]-1))]\n",
    "            df_blue_out[\"LED_Intensity\"] = demixed[:N, n]\n",
    "    return df_red_out,df_blue_out\n",
    "\n",
    "\n",
    "# The offset is subtracted to make sure the drift is 0 at the start and at the end between the timestamps.\n",
    "def pred_cpu_ts_from_gpu_ts(gpu, cpu):\n",
    "    # Fit a linear regression model between GPU and CPU timestamps\n",
    "    reg = LinearRegression().fit(gpu.reshape(-1, 1), cpu)\n",
    "    # Use the model to predict CPU timestamps\n",
    "    reg_ts = reg.predict(gpu.reshape(-1, 1))\n",
    "    # Calculate the mean difference between the predicted and actual CPU timestamps for the first 1000 samples\n",
    "    offset = (reg_ts - cpu)[:1000].mean()\n",
    "    # Adjust the predicted CPU timestamps by the offset\n",
    "    Corr_ts = reg_ts - offset\n",
    "    print(f\"gpu ts:{gpu[0]}, cpu_ts: {cpu[0]}, reg_ts: {reg_ts[0]}, offset: {offset}, corrected ts:{Corr_ts[0]}\")\n",
    "    return Corr_ts\n",
    "\n",
    "\n",
    "# # Function without subtracting offset\n",
    "# # FOr visualisation check helper function vis_gpu_cpu_ts\n",
    "# def pred_cpu_ts_from_gpu_ts(gpu_train, cpu_train, gpu_test,cpu_test_eval=None):\n",
    "#     reg = LinearRegression().fit(gpu_train.reshape(-1, 1), cpu_train)\n",
    "#     print(\"Regression coefficients of GPU2CPU linear model:\",reg.coef_)\n",
    "#     pred_cpu = reg.predict(gpu_test.reshape(-1, 1))\n",
    "#     pred_score = None\n",
    "#     # If true dio values are passed in inputs, compute R-squared scores for performance\n",
    "#     if cpu_test_eval is not None:\n",
    "#         pred_score = reg.score(gpu_test.reshape(-1, 1),cpu_test_eval)\n",
    "#     return pred_cpu,pred_score\n",
    "\n",
    "def vis_gpu_cpu_ts(path='/home/genzel/param/sync_inp_files'):\n",
    "    # Verify the gpu vs cpu timestamp relationship\n",
    "    path = Path(path).resolve()\n",
    "    meta_filepath_list = list(sorted(path.glob('*.meta')))\n",
    "    for filepath in meta_filepath_list:\n",
    "        ts_data = np.genfromtxt(filepath, delimiter=',', names=True)\n",
    "    #     print(ts_data['callback_gpu_ts'], ts_data['callback_clock_ts'])\n",
    "    \n",
    "        corr_cpu_ts = pred_cpu_ts_from_gpu_ts(ts_data['callback_gpu_ts'], ts_data['callback_clock_ts'])\n",
    "        df = pd.DataFrame()\n",
    "        df['extracted_seconds_timestamp'] = pd.to_datetime(corr_cpu_ts,unit='s',utc=True)\n",
    "        df['extracted_seconds_timestamp'] = df['extracted_seconds_timestamp'].dt.tz_convert('CET').dt.tz_localize(\n",
    "            None)\n",
    "    #     print(\"R squared score of the GPU2CPU linear model: \",pred_score)\n",
    "        error = ts_data['callback_clock_ts'] - corr_cpu_ts\n",
    "        plt.figure()\n",
    "        plt.plot(error)\n",
    "        plt.title(\"Error in original and predicted CPU timestamp\")\n",
    "        plt.show()\n",
    "        plt.figure()\n",
    "        plt.plot(ts_data['callback_gpu_ts']- ts_data['callback_clock_ts'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ec7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_metadata(file_path,xy_coord,meta_filepath,process_frame_count):\n",
    "    cap = cv2.VideoCapture(str(file_path))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames_to_process = process_frame_count if process_frame_count is not None else frame_count\n",
    "    \n",
    "    # read time stamps from the meta file : alternative but uncorrected\n",
    "    # Getting the data from the metadata files\n",
    "    ts_data = np.genfromtxt(meta_filepath, delimiter=',', names=True)\n",
    "\n",
    "    # Correcting the timestamps from meta file using linear regression\n",
    "    corr_cpu_ts = pred_cpu_ts_from_gpu_ts(ts_data['callback_gpu_ts'], ts_data['callback_clock_ts'])\n",
    "    df = pd.DataFrame()\n",
    "    df['extracted_seconds_timestamp'] = pd.to_datetime(corr_cpu_ts,unit='s',utc=True)\n",
    "    df['extracted_seconds_timestamp'] = df['extracted_seconds_timestamp'].dt.tz_convert('CET').dt.tz_localize(\n",
    "        None)\n",
    "\n",
    "    # extract time stamps from the csv files based on sync_edited: as they are corrected timestamps\n",
    "    # Not using this since meta files can be used instead of csv and csv vs meta values didnt match \n",
    "    # with linear regression\n",
    "#     df = pd.read_csv(str(ts_file_path), sep=',',parse_dates=['Timestamps_M'])#dtype=str)\n",
    "#     df['extracted_seconds_timestamp'] = pd.to_datetime(df['Timestamps_M'], unit='s',utc=True)\n",
    "#     df['extracted_seconds_timestamp'] = df['extracted_seconds_timestamp'].dt.tz_convert('CET').dt.tz_localize(None)\n",
    "#     print(df['extracted_seconds_timestamp']) # time_meta \n",
    "#     print(df['extracted_seconds_timestamp'][0].value/ 10**9) # time_meta \n",
    "    \n",
    "    \n",
    "    \n",
    "#     df = pd.read_csv(str(ts_file_path), sep=',',parse_dates=['callback_clock_ts'])#dtype=str)\n",
    "#     df['extracted_seconds_timestamp'] = pd.to_datetime(df['callback_clock_ts'], unit='s')\n",
    "    \n",
    "    if(frame_count != len(df['extracted_seconds_timestamp'])):\n",
    "        print(\"Frame counts do not match!!!\")\n",
    "        print(f\"Frame count from video({frame_count})\")\n",
    "        print(f\"Frame count from metadata({len(df['extracted_seconds_timestamp'])})\")\n",
    "    \n",
    "              \n",
    "    rgb_frames = np.empty((frames_to_process,16,16,3))\n",
    "#     while(cap.isOpened()):\n",
    "    for i in range(frames_to_process):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Start coordinate, here (5, 5)\n",
    "        # represents the top left corner of rectangle\n",
    "        start_point = (xy_coord[0]-8, xy_coord[1]-8)\n",
    "\n",
    "\n",
    "        frame = frame[start_point[1]:start_point[1]+16,start_point[0]:start_point[0]+16]\n",
    "#         rgb_frames = np.append(rgb_frames,frame.reshape(-1, 16, 16, 3), axis=0)\n",
    "        rgb_frames[i,:,:,:] = frame\n",
    "#         cv2.imshow('ImageWindow', frame)\n",
    "#         cv2.waitKey(1)\n",
    "        if i % 1000 == 0:\n",
    "            print(i,datetime.now(),end='\\r')\n",
    "#     print(rgb_frames)\n",
    "#     cv2.destroyAllWindows()\n",
    "#     cv2.waitKey(1)\n",
    "    cap.release()\n",
    "    # number of components to extract from image crops: blue, red and noise\n",
    "    nc = 3 \n",
    "    ica = FastICA(n_components=nc, random_state=0)\n",
    "    # reshape rgb_frames to a 2Darray\n",
    "    X = rgb_frames.reshape(rgb_frames.shape[0], -1).astype(float) \n",
    "#     print(X.shape)\n",
    "    # extraction of the independent signals \n",
    "    demixed = ica.fit_transform(X)\n",
    "    mix_weights = ica.mixing_.mean(axis=0)\n",
    "    \n",
    "    red_ica_df,blue_ica_df = process_ica_signals(demixed,mix_weights,df['extracted_seconds_timestamp'])\n",
    "    \n",
    "    return red_ica_df,blue_ica_df\n",
    "\n",
    "\n",
    "# Code to visualise the red_ica_df\n",
    "#     fig, ax = plt.subplots(1, figsize=(40, 8)) #sharex=\"col\", sharey=True )\n",
    "#     ax.plot(red_ica_df['key'], red_ica_df['Red_LED_Intensity'], c='r')\n",
    "#     ax.set_xlabel('Time')\n",
    "#     ax.set_ylabel('Sum of ICAs (Red LED Intensities) of All Eyes')\n",
    "#     # ax.set_xlim([df_final['key'][0], df_final['key'][width]])\n",
    "#     plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5361ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_com_from_merged_ica(agg_ica):\n",
    "    # threhold\n",
    "    agg_ica_thresh = agg_ica.Total_Intensity > 0\n",
    "    \n",
    "    # Save binarized and summed red ICA and correspnding timstamps\n",
    "    agg_ica_out = pd.DataFrame({'Time_in_seconds' : [], 'ICA' : []})\n",
    "    agg_ica_out.Time_in_seconds = agg_ica['key']\n",
    "    agg_ica_out.ICA = agg_ica_thresh.astype(int)\n",
    "    \n",
    "#     time_ica = ica_red['Time_in_seconds']\n",
    "#     ica_int = ica_red['ICA']\n",
    "    sig_med = np.array(np.diff(agg_ica_out.ICA))\n",
    "    sig_med = np.append(0, sig_med) # why add this 0 ? depends on any condition\n",
    "    rising_edge = np.asarray(np.where(sig_med==1)).flatten()\n",
    "    falling_edge = np.asarray(np.where(sig_med==-1)).flatten()\n",
    "    com_ica = pd.DataFrame({'Center_of_mass' : []})  \n",
    "    if agg_ica_out.Time_in_seconds[rising_edge[0]] < agg_ica_out.Time_in_seconds[falling_edge[0]]:  \n",
    "        for i in range(min(len(rising_edge), len(falling_edge))):\n",
    "            com_ica.at[i, 'Center_of_mass'] = agg_ica_out.Time_in_seconds[rising_edge[i]]\n",
    "            +(agg_ica_out.Time_in_seconds[falling_edge[i]]\n",
    "              -agg_ica_out.Time_in_seconds[rising_edge[i]])/2\n",
    "    else:\n",
    "        for i in range(min(len(rising_edge), len(falling_edge))-1):\n",
    "            com_ica.at[i, 'Center_of_mass'] = agg_ica_out.Time_in_seconds[rising_edge[i]]\n",
    "            +(agg_ica_out.Time_in_seconds[falling_edge[i+1]]\n",
    "              -agg_ica_out.Time_in_seconds[rising_edge[i]])/2\n",
    "    return com_ica\n",
    "\n",
    "\n",
    "def merge_ica_and_extract_com(red_ica_list,blue_ica_list):\n",
    "    # merge all eye data when running for all eyes\n",
    "    it = iter(range(len(red_ica_list))) \n",
    "    red_ica_total = ft.reduce(lambda left, right: pd.merge(left, right, on='key', how='outer', \n",
    "                                                      suffixes=(None,\"_\"+str(next(it)))), \n",
    "                              red_ica_list)\n",
    "    red_ica_total = red_ica_total.sort_values('key')\n",
    "#     print(\"Before interpolation:\",red_ica_total.isnull().sum())\n",
    "    for column in red_ica_total.columns:\n",
    "        if column == 'key':\n",
    "            continue\n",
    "        else:\n",
    "            red_ica_total[column] = red_ica_total[column].interpolate()\n",
    "#     red_ica_total.filter(like='LED_Intensity').interpolate(inplace=True)\n",
    "    #red_ica_total.interpolate(inplace=True)# red_ica_total.fillna(0) # red_ica_total.filter(like='LED_Intensity').interpolate(inplace=True) #\n",
    "#     print(\"After interpolation:\",red_ica_total.isnull().sum())\n",
    "    \n",
    "    it = iter(range(len(blue_ica_list)))                          \n",
    "    blue_ica_total = ft.reduce(lambda left, right: pd.merge(left, right, on='key', how='outer', \n",
    "                                                      suffixes=(None,\"_\"+str(next(it)))),\n",
    "                               blue_ica_list)  \n",
    "    blue_ica_total = blue_ica_total.sort_values('key')\n",
    "#     print(\"Before interpolation:\",blue_ica_total.isnull().sum())\n",
    "    for column in blue_ica_total.columns:\n",
    "        if column == 'key':\n",
    "            continue\n",
    "        else:\n",
    "            blue_ica_total[column] = blue_ica_total[column].interpolate()\n",
    "#     print(\"After interpolation:\",blue_ica_total.isnull().sum())\n",
    "    \n",
    "    red_ica_total['Total_Intensity'] = red_ica_total.filter(like='LED_Intensity').sum(1)\n",
    "    blue_ica_total['Total_Intensity'] = blue_ica_total.filter(like='LED_Intensity').sum(1)\n",
    "    \n",
    "    red_ica_total = red_ica_total[['key', 'Total_Intensity']]\n",
    "    red_ica_total = red_ica_total.reset_index(drop=True)\n",
    "    blue_ica_total = blue_ica_total[['key', 'Total_Intensity']]\n",
    "    blue_ica_total = blue_ica_total.reset_index(drop=True)\n",
    "#     print(red_ica_total)\n",
    "#     print(blue_ica_total)\n",
    "#     fig, ax = plt.subplots(1, figsize=(40, 8))\n",
    "#     ax.plot(red_ica_total['key'], red_ica_total['Total_Intensity'], c='r')\n",
    "#     ax.plot(blue_ica_total['key'], blue_ica_total['Total_Intensity'], c='b')\n",
    "\n",
    "\n",
    "    # get centre of mass for both aggregated signals\n",
    "    red_ica_com = extract_com_from_merged_ica(red_ica_total)\n",
    "    blue_ica_com = extract_com_from_merged_ica(blue_ica_total)\n",
    "    \n",
    "    return red_ica_com, blue_ica_com, red_ica_total, blue_ica_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00fc2a",
   "metadata": {},
   "source": [
    "# Functions to extract DIO signals and centre of mass from metadata files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b82334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract DIOS\n",
    "\n",
    "def readTrodesExtractedDataFile(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Check if first line is start of settings block\n",
    "        if f.readline().decode('ascii').strip() != '<Start settings>':\n",
    "            raise Exception(\"Settings format not supported\")\n",
    "        fields = True\n",
    "        fieldsText = {}\n",
    "        for line in f:\n",
    "            # Read through block of settings\n",
    "            if(fields):\n",
    "                line = line.decode('ascii').strip()\n",
    "                # filling in fields dict\n",
    "                if line != '<End settings>':\n",
    "                    vals = line.split(': ')\n",
    "                    fieldsText.update({vals[0].lower(): vals[1]})\n",
    "                # End of settings block, signal end of fields\n",
    "                else:\n",
    "                    fields = False\n",
    "                    dt = parseFields(fieldsText['fields'])\n",
    "                    fieldsText['data'] = np.zeros([1], dtype = dt)\n",
    "                    break\n",
    "        # Reads rest of file at once, using dtype format generated by parseFields()\n",
    "        dt = parseFields(fieldsText['fields'])\n",
    "        data = np.fromfile(f, dt)\n",
    "        fieldsText.update({'data': data})\n",
    "        return fieldsText\n",
    "# Parses last fields parameter (<time uint32><...>) as a single string\n",
    "# Assumes it is formatted as <name number * type> or <name type>\n",
    "# Returns: np.dtype\n",
    "def parseFields(fieldstr):\n",
    "    # Returns np.dtype from field string\n",
    "    sep = re.split('\\s', re.sub(r\"\\>\\<|\\>|\\<\", ' ', fieldstr).strip())\n",
    "    # print(sep)\n",
    "    typearr = []\n",
    "    # Every two elmts is fieldname followed by datatype\n",
    "    for i in range(0,sep.__len__(), 2):\n",
    "        fieldname = sep[i]\n",
    "        repeats = 1\n",
    "        ftype = 'uint32'\n",
    "        # Finds if a <num>* is included in datatype\n",
    "        if sep[i+1].__contains__('*'):\n",
    "            temptypes = re.split('\\*', sep[i+1])\n",
    "            # Results in the correct assignment, whether str is num*dtype or dtype*num\n",
    "            ftype = temptypes[temptypes[0].isdigit()]\n",
    "            repeats = int(temptypes[temptypes[1].isdigit()])\n",
    "        else:\n",
    "            ftype = sep[i+1]\n",
    "        try:\n",
    "            fieldtype = getattr(np, ftype)\n",
    "        except AttributeError:\n",
    "            print(ftype + \" is not a valid field type.\\n\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            typearr.append((str(fieldname), fieldtype, repeats))\n",
    "    return np.dtype(typearr)\n",
    "\n",
    "\n",
    "def extract_dio_com(dio_file_path_dict):\n",
    "    sys_time_dict = readTrodesExtractedDataFile(dio_file_path_dict['init'][0])\n",
    "    sys_time = int(sys_time_dict['system_time_at_creation'])/1000\n",
    "    timestamp_at_creation = int(sys_time_dict['timestamp_at_creation'])#/1000\n",
    "    sys_time_dt = datetime.utcfromtimestamp(sys_time)#pd.to_datetime(sys_time, unit='s',utc=True)#\n",
    "#     print(pd.to_datetime(sys_time, unit='s'),sys_time_dt,datetime.utcfromtimestamp(timestamp_at_creation/1000))\n",
    "    print(sys_time,sys_time_dt)\n",
    "    red_dict_dio = readTrodesExtractedDataFile(dio_file_path_dict['red'][0])\n",
    "    red_DIO = red_dict_dio['data']\n",
    "    \n",
    "    red_DIO_ts = [((sys_time_dt + timedelta(seconds = (i[0]-timestamp_at_creation)/ 30000)).timestamp(),\n",
    "                   i[1]) for i in red_DIO]\n",
    "#     print(red_DIO)\n",
    "    red_DIO_df  = pd.DataFrame({\"Time_Stamp_(DIO)\" : [datetime.fromtimestamp(i[0]) for i in red_DIO_ts], \n",
    "                                \"Time_in_seconds_(DIO)\" : [str(i[0]) for i in red_DIO_ts], \n",
    "                                \"State\": [i[1] for i in red_DIO_ts]} )\n",
    "#     print(red_DIO_ts)\n",
    "#     print(red_DIO_df)\n",
    "    \n",
    "    blue_dict_dio = readTrodesExtractedDataFile(dio_file_path_dict['blue'][0])\n",
    "    blue_DIO = blue_dict_dio['data']\n",
    "    blue_DIO_ts = [((sys_time_dt + timedelta(seconds = (i[0]-timestamp_at_creation)/ 30000)).timestamp() , \n",
    "                    i[1]) for i in blue_DIO]\n",
    "    blue_DIO_df  = pd.DataFrame({\"Time_Stamp_(DIO)\" : [datetime.fromtimestamp(i[0]) for i in blue_DIO_ts], \n",
    "                                 \"Time_in_seconds_(DIO)\" : [str(i[0]) for i in blue_DIO_ts], \n",
    "                                 \"State\": [i[1] for i in blue_DIO_ts]} )\n",
    "    \n",
    "#     # Visualise DIO raw signals\n",
    "#     fig, ax = plt.subplots()\n",
    "#     h1 = ax.stem(red_DIO_df[\"Time_Stamp_(DIO)\"], red_DIO_df[\"State\"],'red',markerfmt='ro') #markerfmt=' '\n",
    "#     h2 = ax.stem(blue_DIO_df[\"Time_Stamp_(DIO)\"], blue_DIO_df[\"State\"],'blue',markerfmt='bo') #markerfmt=' '\n",
    "    \n",
    "#     proxies = [h1,h2]\n",
    "#     legend_names = ['Red_DIO','Blue_DIO']\n",
    "#     plt.legend(proxies, legend_names, loc='best', numpoints=1)\n",
    "#     for h in proxies:\n",
    "#         h.set_visible(False)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    com_dio_red = pd.DataFrame({'Center_of_mass' : []})\n",
    "    if red_DIO_df[\"State\"][0]==1:\n",
    "        for i in range(2, len(red_DIO_df[\"State\"]), 2):\n",
    "            com_dio_red.at[(i-2)/2, 'Center_of_mass'] = red_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(red_DIO_df[\"Time_Stamp_(DIO)\"][i]-red_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "    else:\n",
    "        for i in range(3, len(red_DIO_df[\"State\"]), 2):\n",
    "            com_dio_red.at[(((i-1)/2)-1), 'Center_of_mass'] = red_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(red_DIO_df[\"Time_Stamp_(DIO)\"][i]-red_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "            \n",
    "    \n",
    "    com_dio_blue = pd.DataFrame({'Center_of_mass' : []})\n",
    "    if blue_DIO_df[\"State\"][0]==1:\n",
    "        for i in range(2, len(blue_DIO_df[\"State\"]), 2):\n",
    "            com_dio_blue.at[(i-2)/2, 'Center_of_mass'] = blue_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(blue_DIO_df[\"Time_Stamp_(DIO)\"][i]-blue_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "    else:\n",
    "        for i in range(3, len(blue_DIO_df[\"State\"]), 2):\n",
    "            com_dio_blue.at[(((i-1)/2)-1), 'Center_of_mass'] = blue_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(blue_DIO_df[\"Time_Stamp_(DIO)\"][i]-blue_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "    return com_dio_red,com_dio_blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf18ae",
   "metadata": {},
   "source": [
    "# Function to visualise the ICA and DIO COMs, verify the initial shift and constant delay between signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0f7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_ica_dio_coms(dio_com_red,ica_com_red,dio_com_blue,ica_com_blue):    \n",
    "    dio_com_red[\"Amp\"] = 0.6\n",
    "    ica_com_red[\"Amp\"] = 0.6\n",
    "    dio_com_blue[\"Amp\"] = 0.5\n",
    "    ica_com_blue[\"Amp\"] = 0.5\n",
    "    # dio_com[\"Center_of_mass\"] = pd.to_datetime(dio_com[\"Center_of_mass\"])\n",
    "\n",
    "    # ax1 = dio_com_red.plot(kind='scatter', x=\"Center_of_mass\", y='Amp', color='r') \n",
    "    # ax2 = ica_com_red.plot(kind='scatter', x=\"Center_of_mass\", y='Amp', color='orange',ax=ax1)\n",
    "    # ax3 = ica_com_blue.plot(kind='scatter', x=\"Center_of_mass\", y='Amp', color='b',ax=ax1)\n",
    "    # ax3 = dio_com_blue.plot(kind='scatter', x=\"Center_of_mass\", y='Amp', color='c',ax=ax1)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    h1 = ax.stem(dio_com_red[\"Center_of_mass\"], dio_com_red[\"Amp\"],'red',markerfmt='ro') #markerfmt=' '\n",
    "    h2 = ax.stem(ica_com_red[\"Center_of_mass\"], ica_com_red[\"Amp\"],'orange',markerfmt='yo')\n",
    "\n",
    "    h3 = ax.stem(dio_com_blue[\"Center_of_mass\"], dio_com_blue[\"Amp\"],'blue',markerfmt='bo')\n",
    "    h4 = ax.stem(ica_com_blue[\"Center_of_mass\"], ica_com_blue[\"Amp\"],'cyan',markerfmt='co')\n",
    "    \n",
    "    proxies = [h1,h2,h3,h4]\n",
    "    legend_names = ['Red_DIO','Red_ICA','Blue_DIO','Blue_ICA']\n",
    "    plt.legend(proxies, legend_names, loc='best', numpoints=1)\n",
    "#     for h in proxies:\n",
    "#         h.set_visible(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a60b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Assuming that this model will be specific to each set of eye videos\n",
    "We train the model everytime and predict the timestamps\n",
    "The predicted timestamps will have some error so ultimately a closest dio time stamp to the \n",
    "predicted dio time stamp shall be chosen for analysis.'''\n",
    "\n",
    "# Old one without offset\n",
    "# def pred_dio_ts_from_ica_ts(ica_train, dio_train, ica_test,dio_test_eval=None):\n",
    "#     reg = LinearRegression().fit(ica_train.reshape(-1, 1), dio_train)\n",
    "#     print(\"Regression coefficients of ICA2DIO linear model:\",reg.coef_)\n",
    "#     pred_dio = reg.predict(ica_test.reshape(-1, 1))\n",
    "#     pred_score = None\n",
    "#     # If true dio values are passed in inputs, compute R-squared scores for performance\n",
    "#     if dio_test_eval is not None:\n",
    "#         pred_score = reg.score(ica_test.reshape(-1, 1),dio_test_eval)\n",
    "#     return pred_dio,pred_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# New one with offset\n",
    "def pred_dio_ts_from_ica_ts_and_verify(ica_train, dio_train,test_cpu_blue,test_cpu_red,frame_wise_ts,\n",
    "                                       vis_on=False):\n",
    "    reg = LinearRegression().fit(ica_train.reshape(-1, 1), dio_train)\n",
    "#     print(\"Regression coefficients of ICA2DIO linear model:\",reg.coef_)\n",
    "    pred_dio_blue = reg.predict(test_cpu_blue.reshape(-1, 1))\n",
    "    pred_dio_red = reg.predict(test_cpu_red.reshape(-1, 1))\n",
    "    pred_frame_wise_ts = reg.predict(frame_wise_ts.reshape(-1, 1))\n",
    "    offset_red = pred_dio_red[0] - test_cpu_red[0]\n",
    "    offset_blue = pred_dio_blue[0] - test_cpu_blue[0]\n",
    "    assert offset_red == offset_blue, f\"Offset in red({offset_red}) and blue ({offset_blue})signal is not same\"\n",
    "    print(\"Offset for final correction(s) is: \",offset_red)\n",
    "    pred_dio_blue = pred_dio_blue - offset_blue\n",
    "    pred_dio_red = pred_dio_red - offset_red\n",
    "    pred_frame_wise_ts = pred_frame_wise_ts - offset_red\n",
    "    # Try dio test instead of testcpu\n",
    "    if vis_on:\n",
    "        plt.figure()\n",
    "        plt.plot(pred_dio_blue)\n",
    "        plt.title(\"Predicted ts vs Frame number\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(pred_dio_blue - test_cpu_blue)\n",
    "        plt.title(\"Predicted ts-cpu vs Frame number\")\n",
    "        plt.show()\n",
    "        \n",
    "        val_dio = reg.predict(ica_train.reshape(-1, 1))\n",
    "        plt.figure()\n",
    "        plt.plot(val_dio - dio_train)\n",
    "        plt.title(\"pred dio on train - dio ground truth vs Frame number\")\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(pred_frame_wise_ts - frame_wise_ts)\n",
    "        plt.title(\"pred framewise ts - cpu avg framewise ts vs Frame number\")\n",
    "        plt.show()\n",
    "    return pred_dio_blue,pred_dio_red,pred_frame_wise_ts\n",
    "\n",
    "\n",
    "# Finding first overlap needs to be after the first DIO signals in red/blue\n",
    "def trim_ts_before_first_overlap(ica_ts_red,dio_ts_red,ica_ts_blue,dio_ts_blue):\n",
    "    start_point_ica= 0\n",
    "    # trimmed dio is the first and last signal removed\n",
    "    trimmed_dio_red = dio_ts_red.values[1:-2]\n",
    "    print(f\"trimmed dio len: {trimmed_dio_red.shape}, before trim: {dio_ts_red.shape} \")\n",
    "    trimmed_ica_red_front = ica_ts_red[(ica_ts_red > dio_ts_red.values[0])].to_numpy()\n",
    "    print(f\"trimmed ica front len: {trimmed_ica_red_front.shape}, before trim: {ica_ts_red.shape} \")\n",
    "    trimmed_ica_red = trimmed_ica_red_front[start_point_ica:len(trimmed_dio_red)+start_point_ica]\n",
    "    print(f\"trimmed ica len: {trimmed_ica_red.shape}, before trim: {ica_ts_red.shape} \")\n",
    "    # trimmed ica is the ma\n",
    "    \n",
    "    # trimmed ica signals to start after the timestamp when DIO was initialised\n",
    "    # trimmed ica signals to end before the last DIO since that might be corrupted when switched off.\n",
    "#     trimmed_ica = ica_ts[(ica_ts > dio_ts.values[0]) & (ica_ts < dio_ts.values[-2])].to_numpy()\n",
    "    \n",
    "    # After the signal is trimmed, need to check if there are any outliers or abnormal shifts\n",
    "#     trimmed_dio = dio_ts.to_numpy()[1:len(trimmed_ica)+1]\n",
    "    diff = trimmed_dio_red - trimmed_ica_red\n",
    "    print(\"Red: Trimmed dio - Trimmed ICA difference is: \",diff)\n",
    "    plt.figure()\n",
    "    plt.plot(diff)\n",
    "    plt.title(\"diff between RED : trimmed dio and trimmed ica vs Frame number\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # trimmed dio is the first and last signal removed\n",
    "    trimmed_dio_blue = dio_ts_blue[(dio_ts_blue > dio_ts_red.values[0]) & \n",
    "                                   (dio_ts_blue < dio_ts_red.values[-1])].to_numpy()\n",
    "    print(f\"trimmed dio len: {trimmed_dio_blue.shape}, before trim: {dio_ts_blue.shape} \")\n",
    "    trimmed_ica_blue_front = ica_ts_blue[(ica_ts_blue > dio_ts_red.values[0])].to_numpy()\n",
    "    print(f\"trimmed ica front len: {trimmed_ica_blue_front.shape}, before trim: {ica_ts_blue.shape} \")\n",
    "    trimmed_ica_blue = trimmed_ica_blue_front[5*start_point_ica:len(trimmed_dio_blue)+5*start_point_ica]\n",
    "    print(f\"trimmed ica len: {trimmed_ica_blue.shape}, before trim: {ica_ts_blue.shape} \")\n",
    "    # trimmed ica is the ma\n",
    "    \n",
    "    # trimmed ica signals to start after the timestamp when DIO was initialised\n",
    "    # trimmed ica signals to end before the last DIO since that might be corrupted when switched off.\n",
    "#     trimmed_ica = ica_ts[(ica_ts > dio_ts.values[0]) & (ica_ts < dio_ts.values[-2])].to_numpy()\n",
    "    \n",
    "    # After the signal is trimmed, need to check if there are any outliers or abnormal shifts\n",
    "#     trimmed_dio = dio_ts.to_numpy()[1:len(trimmed_ica)+1]\n",
    "    diff = trimmed_dio_blue - trimmed_ica_blue\n",
    "    print(\"Trimmed dio - Trimmed ICA difference is: \",diff)\n",
    "    plt.figure()\n",
    "    plt.plot(diff)\n",
    "    plt.title(\"diff between trimmed dio and trimmed ica vs Frame number\")\n",
    "    plt.show()\n",
    "    \n",
    "    return trimmed_ica_red,trimmed_dio_red,trimmed_ica_blue,trimmed_dio_blue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e52c8",
   "metadata": {},
   "source": [
    "# Main code using previously defined functions to generate ICA vs DIO visualisation and sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_path = '/home/genzel/param/sync_inp_files'\n",
    "out_path = '/home/genzel/param/outpath/'\n",
    "# Get file list paths and the metadata paths related to it : dio timestamps, xy co-ords, ???\n",
    "vfl,xy_dict,meta_file_list,dio_file_path_dict = get_video_files_with_metadata(inp_path)\n",
    "\n",
    "\n",
    "\n",
    "#TODO: Verify the list from user\n",
    "# print(vfl,xy_dict,tsfl,dio_file_path_dict)\n",
    "print(meta_file_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1108094a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop over each video file to get the df\n",
    "red_ica_list = []\n",
    "blue_ica_list = []\n",
    "process_frame_count = None\n",
    "for itr,video_file_path in enumerate(vfl):\n",
    "    print(\"Processing for eye:\",itr)\n",
    "    print(\"Filepath:\",video_file_path)\n",
    "    print(\"XY coordinates for crop:\",xy_dict[str(video_file_path)])\n",
    "    \n",
    "    red_ica_out,blue_ica_out = process_video_with_metadata(video_file_path,xy_dict[str(video_file_path)],\n",
    "                                                           meta_file_list[itr],process_frame_count)\n",
    "    if (red_ica_out is not None) and (blue_ica_out is not None): \n",
    "        red_ica_list.append(red_ica_out)\n",
    "        blue_ica_list.append(blue_ica_out)\n",
    "        print(\"=================\")\n",
    "    else:\n",
    "        print(\"CORRUPTED SIGNAL/VIDEO CROP....IGNORING:\",str(video_file_path))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda48464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average of the timestamps extracted from each eye video frame. \n",
    "# TODO: Discuss whats the best strategy to calculate the timestamp for stitched frame\n",
    "# 1. Choose ts of eye as per rat position 2. Remove unused eyes and average 3. Use all eyes data\n",
    "# Current strategy is 2\n",
    "final_size = min([eye_ts.shape[0] for eye_ts in blue_ica_list])\n",
    "print(final_size)\n",
    "sum_ts = np.zeros((final_size,))\n",
    "print(sum_ts)\n",
    "for item in blue_ica_list:\n",
    "    ts_df = pd.to_datetime(item['key']).astype(int)/ 10**9\n",
    "    print(ts_df[0],ts_df[1])\n",
    "    sum_ts = sum_ts + ts_df.to_numpy()[:final_size]\n",
    "    \n",
    "avg_ts_per_frame = sum_ts/len(blue_ica_list)\n",
    "avg_ts_per_frame[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92663f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process the combined ica signals and get centre of mass for the aggregated signal from all eyes\n",
    "ica_com_red,ica_com_blue, red_ica_total, blue_ica_total = merge_ica_and_extract_com(red_ica_list,blue_ica_list)\n",
    "\n",
    "# extract dio signal, time stamps, \n",
    "# process the dio signals and timestamps, and \n",
    "# get centre of mass for dio signals\n",
    "dio_com_red, dio_com_blue = extract_dio_com(dio_file_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_ica_dio_coms(dio_com_red,ica_com_red,dio_com_blue,ica_com_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd294b03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ts_ica_red = pd.to_datetime(ica_com_red['Center_of_mass']).astype(int)/ 10**9\n",
    "ts_dio_red = pd.to_datetime(dio_com_red['Center_of_mass']).astype(int)/ 10**9\n",
    "\n",
    "ts_dio_blue = pd.to_datetime(dio_com_blue['Center_of_mass']).astype(int)/ 10**9\n",
    "ts_ica_blue = pd.to_datetime(ica_com_blue['Center_of_mass']).astype(int)/ 10**9\n",
    "\n",
    "\n",
    "ica_train_red, dio_train_red, ica_train_blue, dio_train_blue = trim_ts_before_first_overlap(ts_ica_red, \n",
    "                                                                                            ts_dio_red, \n",
    "                                                                                            ts_ica_blue, \n",
    "                                                                                            ts_dio_blue)\n",
    "red_ica_corrected_s = pd.to_datetime(red_ica_total['key']).astype(int)/ 10**9\n",
    "blue_ica_corrected_s = pd.to_datetime(blue_ica_total['key']).astype(int)/ 10**9\n",
    "print(\"Red ICA total timestamps:\",red_ica_corrected_s.to_numpy())\n",
    "# Train on red and test on blue\n",
    "# train_set_size = int(0.5 * len(ica_train_red))\n",
    "pred_dio_blue,pred_dio_red,pred_framewise_ts = pred_dio_ts_from_ica_ts_and_verify(ica_train_blue,dio_train_blue,\n",
    "                                                                blue_ica_corrected_s.to_numpy(),\n",
    "                                                                red_ica_corrected_s.to_numpy(),\n",
    "                                                                avg_ts_per_frame,\n",
    "                                                                vis_on=True)\n",
    "print(\"Predicted DIO from regressor:\",pred_dio_blue)\n",
    "# print(dio_train_red[train_set_size:], pred_dio_red)\n",
    "diff = pred_dio_blue - blue_ica_corrected_s.to_numpy()\n",
    "print(\"Min diff in seconds between final corrected vs cpu corrected:\", np.min(diff))\n",
    "print(\"Max diff in seconds between final corrected vs cpu corrected::\", np.max(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the corrected average framewise ts to csv file\n",
    "pred_ts_df = pd.DataFrame(pred_framewise_ts,columns=['Corrected Time Stamp'])\n",
    "pred_ts_df.to_csv(out_path + \"stitched_framewise_ts.csv\",index_label='Frame Number')\n",
    "# blue_ica_corrected_s.to_csv(args.output_path + \"blue_corrected_ts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a410e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualise the gpu and cpu timestamps difference\n",
    "# Check this function definition above\n",
    "vis_gpu_cpu_ts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4f73c",
   "metadata": {},
   "source": [
    "# Auto LED Detection Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_subtract(image_x, image_y):\n",
    "    new_type = np.result_type(image_x, image_y, np.byte)\n",
    "    return (image_x.astype(new_type) - image_y.astype(new_type))\n",
    "\n",
    "def get_led_coords_from_videoframes(file_path,process_frame_count):\n",
    "    cap = cv2.VideoCapture(str(file_path))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames_to_process = process_frame_count if process_frame_count is not None else frame_count\n",
    "              \n",
    "    rgb_frames = np.empty((frames_to_process,16,16,3))\n",
    "    ret, ref_frame = cap.read()\n",
    "    acc_frames = []\n",
    "#     while(cap.isOpened()):\n",
    "    for i in range(frames_to_process):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "#         frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        subtracted = cv2.subtract(frame,ref_frame)\n",
    "        subtracted += cv2.subtract(ref_frame,frame)\n",
    "        th = cv2.threshold(subtracted[100:,:],50,255,cv2.THRESH_BINARY)[1]\n",
    "        acc_frames.append(th)\n",
    "#         ref_frame = frame\n",
    "        # Mask the result with the original image\n",
    "#         masked = cv2.bitwise_and(frame, frame, mask = th)\n",
    "        cv2.imshow('ImageWindow', th)\n",
    "        cv2.waitKey(1)\n",
    "#     print(rgb_frames)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cap.release()\n",
    "    \n",
    "    avg_frame = np.max(acc_frames, axis=0).astype(\"uint8\")\n",
    "    print(avg_frame.shape)\n",
    "    plt.figure()\n",
    "    plt.imshow(avg_frame)\n",
    "    plt.title('my picture')\n",
    "#     plt.show()\n",
    "    avg_frame = cv2.cvtColor(avg_frame, cv2.COLOR_RGB2GRAY)\n",
    "    print(avg_frame.shape)\n",
    "    avg_th = cv2.threshold(avg_frame,0,255,cv2.THRESH_BINARY)[1]\n",
    "    contours = cv2.findContours(avg_th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    print(contours)\n",
    "    for c in contours:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        print(x,y,w,h)\n",
    "        cv2.rectangle(ref_frame, (x, y+100), (x + w, y + 100 + h), (0, 255,0), 2)\n",
    "#     cv2.drawContours(ref_frame, contours, -1, (255,255,255), 3)\n",
    "    plt.figure()\n",
    "    plt.imshow(ref_frame)\n",
    "    plt.title('ref draw')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d16cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = '/home/genzel/param/sync_inp_files/eye10_2020-11-09_12-34-18.mp4'\n",
    "n_frame = 100\n",
    "get_led_coords_from_videoframes(filepath,n_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2375d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Start coordinate, here (5, 5)\n",
    "        # represents the top left corner of rectangle\n",
    "        start_point = (xy_coord[0]-8, xy_coord[1]-8)\n",
    "\n",
    "\n",
    "        frame = frame[start_point[1]:start_point[1]+16,start_point[0]:start_point[0]+16]\n",
    "#         rgb_frames = np.append(rgb_frames,frame.reshape(-1, 16, 16, 3), axis=0)\n",
    "        rgb_frames[i,:,:,:] = frame\n",
    "#         cv2.imshow('ImageWindow', frame)\n",
    "#         cv2.waitKey(1)\n",
    "        if i % 1000 == 0:\n",
    "            print(i,datetime.now(),end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
