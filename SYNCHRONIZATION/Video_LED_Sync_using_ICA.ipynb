{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b89aa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiled from the previous works :\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/synch_editedbyOzge.py\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/Exctract_LEDs_28_01_2023.ipynb\n",
    "# https://github.com/genzellab/HM_RAT/blob/main/SYNCHRONIZATION/synchronization.py\n",
    "\n",
    "# Author: Param Rajpura\n",
    "# 28th May 2023\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm, tnrange\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks,peak_prominences\n",
    "from datetime import datetime , time , timedelta\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443c857",
   "metadata": {},
   "source": [
    "# Extract file paths from the user defined basepath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a1c1614b",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    " The basepath must contain the following files:\n",
    " 1. Eye video files: .mp4 formats (12 files for each eye)\n",
    " 2. X,y co-ordinates of crops for LED positions : .led_crop format (1 file containing 12 xy co-ordinates)\n",
    " 3. Time stamp files containing framewise clock timestamps after linear regression: .csv format (12 files)\n",
    " 4. Time stamps recorded from LED controller referred to as DIO: .dat format (3 files for red,blue and \n",
    " initial systime)\n",
    " '''\n",
    "\n",
    "\n",
    "# Reads all the mp4 files in the folder, checks for a led_crop_coordinates file and meta file\n",
    "def get_video_files_with_metadata(basepath,led_xy=True,time_stamp=True):\n",
    "    path = Path(basepath).resolve()\n",
    "    videos_filepath_list = list(sorted(path.glob('*.mp4')))\n",
    "#     print(videos_filepath_list)\n",
    "    \n",
    "    crop_xy_dict = {}\n",
    "    # Verify if led_coordinates supplied\n",
    "    if led_xy:\n",
    "        crop_file_list = list(sorted(path.glob('*.led_crop')))\n",
    "#         print(crop_file_list)\n",
    "        if crop_file_list:\n",
    "            # read crops coords for each video and store\n",
    "            with open(crop_file_list[0]) as f:\n",
    "                crop_txt = f.readlines()\n",
    "#                 print(crop_txt)\n",
    "            for line in tqdm(crop_txt):\n",
    "                try:\n",
    "                    vid_path, x, y = line.split(',')\n",
    "                    crop_xy_dict[vid_path] = (int(x), int(y))\n",
    "                except ValueError:\n",
    "                    print(\"Faulty line:\", line, 'Maybe led coordinates are missing?')\n",
    "                    break\n",
    "        else:\n",
    "            raise Exception(\"File containing led crop coordinates not found.\")\n",
    "    if time_stamp:\n",
    "        tsdata_filepath_list = list(sorted(path.glob('*.csv')))\n",
    "        \n",
    "    #TODO: Verify for single file path in the list to avoid conflicting data\n",
    "    dio_file_path_dict={}\n",
    "    dio_file_path_dict['init'] = list(sorted(path.glob('*maze.*.dat')))\n",
    "    \n",
    "    dio_file_path_dict['blue'] = list(sorted(path.glob('*maze_merged*Din1.dat')))\n",
    "    dio_file_path_dict['red'] = list(sorted(path.glob('*maze_merged*Din2.dat')))\n",
    "    return videos_filepath_list,crop_xy_dict,tsdata_filepath_list,dio_file_path_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640dc74",
   "metadata": {},
   "source": [
    "# Functions to extract LED signals from video data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "707b68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_red_ica_signal(demixed, mix_weights,time_meta):\n",
    "    fps = 30.0\n",
    "    eD = 0.5       # expected Duty cycle of 0.5\n",
    "    ef_red = 0.5   # expected frequency of 0.5 Hz\n",
    "    ef_blue = 2.5  # expected frequency of 2.5 Hz\n",
    "    \n",
    "    dD = np.zeros(demixed.shape[1])\n",
    "    df_red = np.zeros(demixed.shape[1])\n",
    "    df_blue = np.zeros(demixed.shape[1])\n",
    "    \n",
    "    colors = {0: 'red', 1: 'blue', None: 'gray'}\n",
    "    N = -1\n",
    "    N_ICA = -1  # numbers of samples to use for ICA, -1 for all\n",
    "    \n",
    "    for n in range(demixed.shape[1]):\n",
    "\n",
    "        # Check the mixing weights if the demixed signal polarity is reversed\n",
    "        # (negative weights for ROI. Assuming rest of pixel array has weight zero, mean weight tells us sign.)\n",
    "        flip_ica = mix_weights[n] < 0\n",
    "        if flip_ica:\n",
    "            demixed[:, n] = -demixed[:, n]\n",
    "\n",
    "        km = KMeans(n_clusters=2, random_state=0).fit(demixed[:, n].reshape(-1, 1))\n",
    "        y_km = km.predict(demixed[:, n].reshape(-1, 1))\n",
    "\n",
    "        # check polarity, if necessary flip to match pulse polarity\n",
    "        # print(f'Centers: {float(km.cluster_centers_[0]*1000):.2f}, {float(km.cluster_centers_[1]*1000):.2f}')\n",
    "        centers = km.cluster_centers_.ravel()\n",
    "\n",
    "        flip_kmeans = centers[0] > centers[1]\n",
    "        flip = flip_ica ^ flip_kmeans\n",
    "        # print(f'Polarity FLIP: {flip} (ICA {flip_ica}, kmeans {flip_kmeans})')\n",
    "        if flip_kmeans:\n",
    "            # print('Flipping!')\n",
    "            y_km = np.abs(y_km-1)\n",
    "\n",
    "        duty_cycle = y_km.sum()/len(y_km)\n",
    "        freq = (np.diff(y_km)>0).sum()/len(y_km) * fps\n",
    "        dD[n] = abs(eD-duty_cycle)\n",
    "        df_red[n] = abs(ef_red - freq)\n",
    "        df_blue[n] = abs(ef_blue - freq)\n",
    "\n",
    "        # Attempt to identify the ICA signal as a color LED\n",
    "        good_DC = dD[n] < 0.2 * eD\n",
    "        good_freq = np.array([df_red[n] < ef_red * 0.1, df_blue[n] < ef_blue * 0.1])\n",
    "        is_signal = good_DC and good_freq.sum()\n",
    "        signal_color = good_freq.argmax() if is_signal else None\n",
    "\n",
    "        sig_col = colors[signal_color]\n",
    "        sig_name = 'None' if signal_color is None else colors[signal_color]\n",
    "\n",
    "        if sig_col=='red':\n",
    "            a = y_km[:N]\n",
    "            df_temp = pd.DataFrame({'key' : [], \"Red_LED_Intensity\" : []})\n",
    "            # \"Red_LED_Intensity_%s\" %(eye)\n",
    "            df_temp['key'] = time_meta[0:(len(demixed[:N, n]-1))]\n",
    "            df_temp[\"Red_LED_Intensity\"] = demixed[:N, n]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88ec7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_with_metadata(file_path,xy_coord,ts_file_path,dio_file_path_dict):\n",
    "    cap = cv2.VideoCapture(str(file_path))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # extract time stamps from the csv files based on sync_edited: as they are corrected timestamps\n",
    "    \n",
    "#     data = np.genfromtxt(ts_file_path, delimiter=',', names=True)\n",
    "#     print(data)\n",
    "#     time_meta = data['Timestamps_M']\n",
    "    \n",
    "    #TODO: optimise by reading selected columns\n",
    "    df = pd.read_csv(str(ts_file_path), sep=',',parse_dates=['Timestamps_M'])#dtype=str)\n",
    "    df['extracted_seconds_timestamp'] = pd.to_datetime(df['Timestamps_M'], unit='s')\n",
    "#     print(df['extracted_seconds_timestamp']) # time_meta\n",
    "    \n",
    "    # read time stamps from the meta file : alternative but uncorrected\n",
    "    \n",
    "#     df = pd.read_csv(str(ts_file_path), sep=',',parse_dates=['callback_clock_ts'])#dtype=str)\n",
    "#     df['extracted_seconds_timestamp'] = pd.to_datetime(df['callback_clock_ts'], unit='s')\n",
    "    \n",
    "    assert frame_count == len(df['extracted_seconds_timestamp']),\"Frame count from video and metadata dont match\"\n",
    "    rgb_frames = np.empty((0,16,16,3))\n",
    "#     while(cap.isOpened()):\n",
    "    for i in range(1000):\n",
    "        ret, frame = cap.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Start coordinate, here (5, 5)\n",
    "        # represents the top left corner of rectangle\n",
    "        start_point = (xy_dict[str(vfl[0])][0]-8, xy_dict[str(vfl[0])][1]-8)\n",
    "\n",
    "\n",
    "        frame = frame[start_point[1]:start_point[1]+16,start_point[0]:start_point[0]+16]\n",
    "        rgb_frames = np.append(rgb_frames,frame.reshape(-1, 16, 16, 3), axis=0)\n",
    "#     print(rgb_frames)\n",
    "\n",
    "    # number of components to extract from image crops: blue, red and noise\n",
    "    nc = 3 \n",
    "    ica = FastICA(n_components=nc, random_state=0)\n",
    "    # reshape rgb_frames to a 2Darray\n",
    "    X = rgb_frames.reshape(rgb_frames.shape[0], -1).astype(float) \n",
    "#     print(X.shape)\n",
    "    # extraction of the independent signals \n",
    "    demixed = ica.fit_transform(X)\n",
    "    mix_weights = ica.mixing_.mean(axis=0)\n",
    "    \n",
    "    #TODO: If need to check with blue, get blue_ica_df from the function\n",
    "    red_ica_df = process_red_ica_signal(demixed,mix_weights,df['extracted_seconds_timestamp'])\n",
    "    \n",
    "    return red_ica_df\n",
    "\n",
    "\n",
    "# Code to visualise the red_ica_df\n",
    "#     fig, ax = plt.subplots(1, figsize=(40, 8)) #sharex=\"col\", sharey=True )\n",
    "#     ax.plot(red_ica_df['key'], red_ica_df['Red_LED_Intensity'], c='r')\n",
    "#     ax.set_xlabel('Time')\n",
    "#     ax.set_ylabel('Sum of ICAs (Red LED Intensities) of All Eyes')\n",
    "#     # ax.set_xlim([df_final['key'][0], df_final['key'][width]])\n",
    "#     plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5361ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ica_and_extract_com(eye_ica_list):\n",
    "    # merge all eye data\n",
    "    agg_ica = eye_ica_list\n",
    "    # threhold\n",
    "    agg_ica_thresh = agg_ica.Red_LED_Intensity > 0\n",
    "    \n",
    "    # Save binarized and summed red ICA and correspnding timstamps\n",
    "    agg_ica_out = pd.DataFrame({'Time_in_seconds' : [], 'ICA_red' : []})\n",
    "    agg_ica_out.Time_in_seconds = agg_ica['key']\n",
    "    agg_ica_out.ICA_red = agg_ica_thresh.astype(int)\n",
    "    \n",
    "#     time_ica = ica_red['Time_in_seconds']\n",
    "#     ica_int = ica_red['ICA_red']\n",
    "    red_med = np.array(np.diff(agg_ica_out.ICA_red))\n",
    "    red_med = np.append(0, red_med) # why add this 0 ? depends on any condition\n",
    "    rising_edge_red = np.asarray(np.where(red_med==1)).flatten()\n",
    "    falling_edge_red = np.asarray(np.where(red_med==-1)).flatten()\n",
    "    com_ica = pd.DataFrame({'Center_of_mass' : []})  \n",
    "    if agg_ica_out.Time_in_seconds[rising_edge_red[0]] < agg_ica_out.Time_in_seconds[falling_edge_red[0]]:  \n",
    "        for i in range(min(len(rising_edge_red), len(falling_edge_red))):\n",
    "            com_ica.at[i, 'Center_of_mass'] = agg_ica_out.Time_in_seconds[rising_edge_red[i]]\n",
    "            +(agg_ica_out.Time_in_seconds[falling_edge_red[i]]\n",
    "              -agg_ica_out.Time_in_seconds[rising_edge_red[i]])/2\n",
    "    else:\n",
    "        for i in range(min(len(rising_edge_red), len(falling_edge_red))):\n",
    "            com_ica.at[i, 'Center_of_mass'] = agg_ica_out.Time_in_seconds[rising_edge_red[i]]\n",
    "            +(agg_ica_out.Time_in_seconds[falling_edge_red[i+1]]\n",
    "              -agg_ica_out.Time_in_seconds[rising_edge_red[i]])/2\n",
    "    \n",
    "    return com_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00fc2a",
   "metadata": {},
   "source": [
    "# Functions to extract DIO signals and centre of mass from metadata files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a1b82334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract DIOS\n",
    "\n",
    "def readTrodesExtractedDataFile(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Check if first line is start of settings block\n",
    "        if f.readline().decode('ascii').strip() != '<Start settings>':\n",
    "            raise Exception(\"Settings format not supported\")\n",
    "        fields = True\n",
    "        fieldsText = {}\n",
    "        for line in f:\n",
    "            # Read through block of settings\n",
    "            if(fields):\n",
    "                line = line.decode('ascii').strip()\n",
    "                # filling in fields dict\n",
    "                if line != '<End settings>':\n",
    "                    vals = line.split(': ')\n",
    "                    fieldsText.update({vals[0].lower(): vals[1]})\n",
    "                # End of settings block, signal end of fields\n",
    "                else:\n",
    "                    fields = False\n",
    "                    dt = parseFields(fieldsText['fields'])\n",
    "                    fieldsText['data'] = np.zeros([1], dtype = dt)\n",
    "                    break\n",
    "        # Reads rest of file at once, using dtype format generated by parseFields()\n",
    "        dt = parseFields(fieldsText['fields'])\n",
    "        data = np.fromfile(f, dt)\n",
    "        fieldsText.update({'data': data})\n",
    "        return fieldsText\n",
    "# Parses last fields parameter (<time uint32><...>) as a single string\n",
    "# Assumes it is formatted as <name number * type> or <name type>\n",
    "# Returns: np.dtype\n",
    "def parseFields(fieldstr):\n",
    "    # Returns np.dtype from field string\n",
    "    sep = re.split('\\s', re.sub(r\"\\>\\<|\\>|\\<\", ' ', fieldstr).strip())\n",
    "    # print(sep)\n",
    "    typearr = []\n",
    "    # Every two elmts is fieldname followed by datatype\n",
    "    for i in range(0,sep.__len__(), 2):\n",
    "        fieldname = sep[i]\n",
    "        repeats = 1\n",
    "        ftype = 'uint32'\n",
    "        # Finds if a <num>* is included in datatype\n",
    "        if sep[i+1].__contains__('*'):\n",
    "            temptypes = re.split('\\*', sep[i+1])\n",
    "            # Results in the correct assignment, whether str is num*dtype or dtype*num\n",
    "            ftype = temptypes[temptypes[0].isdigit()]\n",
    "            repeats = int(temptypes[temptypes[1].isdigit()])\n",
    "        else:\n",
    "            ftype = sep[i+1]\n",
    "        try:\n",
    "            fieldtype = getattr(np, ftype)\n",
    "        except AttributeError:\n",
    "            print(ftype + \" is not a valid field type.\\n\")\n",
    "            exit(1)\n",
    "        else:\n",
    "            typearr.append((str(fieldname), fieldtype, repeats))\n",
    "    return np.dtype(typearr)\n",
    "\n",
    "\n",
    "def extract_dio_com(dio_file_path_dict):\n",
    "    sys_time_dict = readTrodesExtractedDataFile(dio_file_path_dict['init'][0])\n",
    "    sys_time = int(sys_time_dict['system_time_at_creation'])/1000\n",
    "    timestamp_at_creation = int(sys_time_dict['timestamp_at_creation'])#/1000\n",
    "    sys_time_dt = datetime.utcfromtimestamp(sys_time)\n",
    "    print(pd.to_datetime(sys_time, unit='s'),sys_time_dt,datetime.utcfromtimestamp(timestamp_at_creation/1000))\n",
    "    \n",
    "    red_dict_dio = readTrodesExtractedDataFile(dio_file_path_dict['red'][0])\n",
    "    red_DIO = red_dict_dio['data']\n",
    "    \n",
    "    red_DIO_ts = [((sys_time_dt + timedelta(seconds = (i[0]-timestamp_at_creation)/ 30000)).timestamp(),\n",
    "                   i[1]) for i in red_DIO]\n",
    "    print(red_DIO)\n",
    "    red_DIO_df  = pd.DataFrame({\"Time_Stamp_(DIO)\" : [datetime.fromtimestamp(i[0]) for i in red_DIO_ts], \n",
    "                                \"Time_in_seconds_(DIO)\" : [str(i[0]) for i in red_DIO_ts], \n",
    "                                \"State\": [i[1] for i in red_DIO_ts]} )\n",
    "#     print(red_DIO_ts)\n",
    "#     print(red_DIO_df)\n",
    "    \n",
    "    blue_dict_dio = readTrodesExtractedDataFile(dio_file_path_dict['blue'][0])\n",
    "    blue_DIO = blue_dict_dio['data']\n",
    "    blue_DIO_ts = [((sys_time_dt + timedelta(seconds = (i[0]-timestamp_at_creation)/ 30000)).timestamp() , \n",
    "                    i[1]) for i in blue_DIO]\n",
    "    blue_DIO_df  = pd.DataFrame({\"Time_Stamp_(DIO)\" : [datetime.fromtimestamp(i[0]) for i in blue_DIO_ts], \n",
    "                                 \"Time_in_seconds_(DIO)\" : [str(i[0]) for i in blue_DIO_ts], \n",
    "                                 \"State\": [i[1] for i in blue_DIO_ts]} )\n",
    "    \n",
    "    \n",
    "    com_dio = pd.DataFrame({'Center_of_mass' : []})\n",
    "    if red_DIO_df[\"State\"][0]==1:\n",
    "        for i in range(2, len(red_DIO_df[\"State\"]), 2):\n",
    "            com_dio.at[(i-2)/2, 'Center_of_mass'] = red_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(red_DIO_df[\"Time_Stamp_(DIO)\"][i]-red_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "    else:\n",
    "        for i in range(3, len(red_DIO_df[\"State\"]), 2):\n",
    "            com_dio.at[(((i-1)/2)-1), 'Center_of_mass'] = red_DIO_df[\"Time_Stamp_(DIO)\"][i-2]\n",
    "            +(red_DIO_df[\"Time_Stamp_(DIO)\"][i]-red_DIO_df[\"Time_Stamp_(DIO)\"][i-2])/2\n",
    "    return com_dio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e52c8",
   "metadata": {},
   "source": [
    "# Main code using previously defined functions to generate ICA vs DIO visualisation and sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "20ec918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050f4e53b095450a8da2794c9d331621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(566, 731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5759/2445062803.py:57: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(typearr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-09 11:33:59.364999936 2020-11-09 11:33:59.365000 1970-01-01 00:23:36.575000\n",
      "[(  2056320, 1) (  2065607, 0) (  2095643, 1) ... (119008823, 1)\n",
      " (119038861, 0) (119068929, 1)]\n",
      "                   Center_of_mass\n",
      "0   1970-01-19 13:48:38.059949640\n",
      "1   1970-01-19 13:48:38.061949280\n",
      "2   1970-01-19 13:48:38.063948920\n",
      "3   1970-01-19 13:48:38.065948550\n",
      "4   1970-01-19 13:48:38.067948190\n",
      "5   1970-01-19 13:48:38.069947830\n",
      "6   1970-01-19 13:48:38.071947470\n",
      "7   1970-01-19 13:48:38.073980430\n",
      "8   1970-01-19 13:48:38.075980070\n",
      "9   1970-01-19 13:48:38.077979710\n",
      "10  1970-01-19 13:48:38.079979340\n",
      "11  1970-01-19 13:48:38.081978980\n",
      "12  1970-01-19 13:48:38.083978620\n",
      "13  1970-01-19 13:48:38.085978260\n",
      "14  1970-01-19 13:48:38.087977890\n",
      "15  1970-01-19 13:48:38.090010860\n",
      "                  Center_of_mass\n",
      "0     2020-11-09 11:34:20.689833\n",
      "1     2020-11-09 11:34:22.000600\n",
      "2     2020-11-09 11:34:24.004133\n",
      "3     2020-11-09 11:34:26.007633\n",
      "4     2020-11-09 11:34:28.011167\n",
      "...                          ...\n",
      "1942  2020-11-09 12:39:11.091500\n",
      "1943  2020-11-09 12:39:13.096033\n",
      "1944  2020-11-09 12:39:15.099567\n",
      "1945  2020-11-09 12:39:17.103067\n",
      "1946  2020-11-09 12:39:19.106600\n",
      "\n",
      "[1947 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get file list paths and the metadata paths related to it : dio timestamps, xy co-ords, ???\n",
    "vfl,xy_dict,tsfl,dio_file_path_dict = get_video_files_with_metadata('./maze_videos/')\n",
    "print(xy_dict[str(vfl[0])])\n",
    "\n",
    "# TODO: loop over each video file to get the df\n",
    "eye_ica_out = process_video_with_metadata(vfl[0],xy_dict[str(vfl[0])],tsfl[0],dio_file_path_dict)\n",
    "\n",
    "\n",
    "\n",
    "# process the combined ica signals and get centre of mass for the aggregated signal from all eyes\n",
    "ica_com = merge_ica_and_extract_com(eye_ica_out)\n",
    "\n",
    "# extract dio signal, time stamps, \n",
    "# process the dio signals and timestamps, and \n",
    "# get centre of mass for dio signals\n",
    "dio_com = extract_dio_com(dio_file_path_dict)\n",
    "\n",
    "print(ica_com)\n",
    "\n",
    "\n",
    "print(dio_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c5d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
